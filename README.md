# Real-Time Audio Classifier for Medical Applications

A machine learning system that classifies environmental sounds in real-time using audio amplitude data collected from mobile devices via PhyPhox. The system is designed for medical and healthcare monitoring applications.

## Overview

This project implements a Support Vector Machine (SVM) classifier that can identify six different types of environmental sounds:

- Silence/ambient noise
- Normal conversation
- Whisper
- Shout/scream
- Music
- Applause

The system processes audio data in real-time using 0.5-second windows and extracts 31 acoustic features to make predictions with confidence scores.

## Key Features

- **Real-time classification**: Processes audio data continuously with 0.5-second windows
- **Medical applications**: Designed for healthcare monitoring, emergency detection, and patient care
- **Mobile integration**: Uses PhyPhox mobile app for data collection
- **High accuracy**: Achieves 96.67% accuracy on validation data
- **Feature engineering**: Extracts 31 statistical and temporal features from audio signals

## Dataset

- **Collection method**: PhyPhox mobile application (sound pressure level sensor)
- **Total samples**: 30 recordings (5 per category)
- **Duration**: 40-60 seconds per recording
- **Features**: 31 extracted features including statistical measures, energy metrics, and temporal derivatives

## Model Performance

The final SVM model with RBF kernel achieved:
- **Validation accuracy**: 96.67%
- **Optimal parameters**: C=20.0, gamma=0.15
- **Feature selection**: SelectKBest with k=10 features

### Comparison with other algorithms:
- Gaussian Naive Bayes: 93%
- Extra Trees: 93%
- Gradient Boosting: 90%
- SVM RBF: 83% (96.67% after optimization)

## Project Structure

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Original CSV files from PhyPhox
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Processed feature files
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ data_acquisition.py     # Data collection from PhyPhox
‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py      # Feature extraction
‚îÇ   ‚îú‚îÄ‚îÄ communication_test.py   # PhyPhox connection testing
‚îÇ   ‚îú‚îÄ‚îÄ data_plot.py           # Real-time visualization
‚îÇ   ‚îú‚îÄ‚îÄ online_prototype.py    # Real-time classifier (inline model)
‚îÇ   ‚îî‚îÄ‚îÄ online_classification.py # Real-time classifier (saved models)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ final_svm_model_svm.pkl        # Trained SVM model
‚îÇ   ‚îú‚îÄ‚îÄ standard_scaler_audio.pkl      # Feature scaler
‚îÇ   ‚îî‚îÄ‚îÄ audio_feature_selector_svm.pkl # Feature selector
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Project.ipynb          # Complete analysis and model development
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ Report.pdf            # Detailed project report
```

## Requirements

- Python 3.x
- scikit-learn
- numpy
- pandas
- scipy
- requests
- matplotlib
- PhyPhox mobile app

## Usage

### Real-time Classification

Para ejecutar el clasificador de audio en tiempo real, sigue estos pasos:

#### Paso 1: Configuraci√≥n de PhyPhox
1. **Instalar PhyPhox**: Descarga e instala la aplicaci√≥n PhyPhox en tu dispositivo m√≥vil:
   - [Android](https://play.google.com/store/apps/details?id=de.rwth_aachen.phyphox)
   - [iOS](https://apps.apple.com/app/phyphox/id1127319693)

2. **Configurar experimento**:
   - Abre PhyPhox y busca el experimento **"Audio Amplitude"**
   - Activa la opci√≥n **"Allow remote access"** en la configuraci√≥n
   - Anota la direcci√≥n IP que aparece en pantalla (ej. `192.168.1.100`)

#### Paso 2: Configuraci√≥n del entorno
1. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Generar modelos entrenados** (si no existen):
   ```bash
   cd notebooks/
   jupyter notebook Proyecto.ipynb
   # Ejecuta todas las celdas hasta la secci√≥n "Clasificaci√≥n en l√≠nea"
   ```

#### Paso 3: Configuraci√≥n de IP
1. **Editar script de clasificaci√≥n**:
   ```bash
   nano scripts/online_classification.py
   ```

2. **Actualizar la IP** en la l√≠nea 46:
   ```python
   IP_ADDRESS = '192.168.1.100'  # Cambia por tu IP de PhyPhox
   ```

#### Paso 4: Ejecutar clasificaci√≥n en tiempo real
1. **Asegurar que los modelos est√©n en la carpeta correcta**:
   ```bash
   ls models/
   # Debe mostrar: final_svm_model_svm.pkl, standard_scaler_audio.pkl, audio_feature_selector_svm.pkl
   ```

2. **Iniciar PhyPhox**: Presiona ‚ñ∂Ô∏è PLAY en el experimento "Audio Amplitude"

3. **Ejecutar clasificador**:
   ```bash
   cd scripts/
   python online_classification.py
   ```

#### Opciones de clasificaci√≥n disponibles:

**Opci√≥n 1: Clasificador con modelos pre-entrenados** (Recomendado)
```bash
python scripts/online_classification.py
```
- Carga modelos desde archivos `.pkl`
- Mayor velocidad de inicio
- Requiere haber ejecutado el notebook previamente

**Opci√≥n 2: Clasificador con entrenamiento inline**
```bash
python scripts/online_prototype.py
```
- Entrena el modelo al inicio usando `audio_features.txt`
- Tarda m√°s en iniciar pero no requiere archivos `.pkl`

#### Resultados esperados:
```
üîä Predicci√≥n #1: CONVERSACION (Conf: 0.87)
üîä Predicci√≥n #2: MUSICA (Conf: 0.92)
üîä Predicci√≥n #3: SILENCIO_AMB (Conf: 0.95)
```

#### Troubleshooting:
- **Error "Archivo no encontrado .pkl"**: Ejecuta el notebook completo primero
- **Error "Timeout"**: Verifica que PhyPhox est√© en PLAY y la IP sea correcta
- **Error "Phyphox status measuring: False"**: Presiona PLAY en PhyPhox
- **Predicciones err√°ticas**: Aseg√∫rate de estar en un ambiente similar al entrenamiento

### Model Training

The complete model development process is available in `notebooks/Proyecto.ipynb`, including:
- Data loading and preprocessing
- Feature extraction
- Model comparison and selection
- Hyperparameter optimization
- Cross-validation results

## Medical Applications

This system can be applied to:
- **Emergency detection**: Identifying screams or calls for help
- **Patient monitoring**: Detecting changes in vocal patterns
- **Environmental control**: Monitoring noise levels in medical facilities
- **Telemedicine**: Remote audio-based symptom analysis
- **Rehabilitation**: Tracking progress in speech therapy

## Real-time Performance

The system shows excellent performance for:
- Silence/ambient: Perfect classification
- Music: Very good (high volume)
- Whispers: Perfect (within specific amplitude range)

Areas for improvement:
- Scream classification: Tends to confuse with music/applause
- Conversation: Requires consistent tone
- Device dependency: Performance varies between different microphones

## Authors

- Andr√©s Mart√≠nez Almaz√°n (A01621042)
- Diego Arechiga Bonilla (A01621045)

**Course**: Modeling Learning with Artificial Intelligence
**Institution**: Tecnol√≥gico de Monterrey
**Professor**: Dr. Omar Mendoza Montoya
**Date**: June 2025

## License

This project was developed for academic purposes as part of a machine learning course.